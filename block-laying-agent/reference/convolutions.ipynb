{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning about Convolutions\n",
    "\n",
    "Learning about convolutions step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolutions\n",
    "\n",
    "Lets start with a 3x4 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Conv1d()`, `in_channels` has to equal 3 since we have 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7338,  2.0918, -2.6176,  3.9756],\n",
       "        [-0.0540, -1.3151,  0.7868, -2.1559],\n",
       "        [ 0.0930,  1.3072, -0.7164,  2.1166]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = torch.nn.Conv1d(in_channels = 3, out_channels = 3, kernel_size = 1)\n",
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the `out_channels` we control the number of rows of the output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3833,  1.4780, -3.2908,  3.3856]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = torch.nn.Conv1d(in_channels = 3, out_channels = 1, kernel_size = 1)\n",
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's change the input tensor just a little bit at `x[1,0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [5., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the same `Conv1d()` over this tensor. \n",
    "\n",
    "(Note that we have not re-initialized the Conv1d function so it is the same Conv1d instance as above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1203,  1.4780, -3.2908,  3.3856]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that only the first item of the output tensor has changed. So Conv1d processes the tensor \"column-by-column\" with an expectation of how many rows/dimensions are in each column based on value set to `in_channels`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Size Changed\n",
    "\n",
    "But now let's run everything again with a different kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3665,  0.5262, -1.1811]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = torch.nn.Conv1d(in_channels = 3, out_channels = 1, kernel_size = 2)\n",
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the size/shape of the output has changed from (1,4) to (1,3).\n",
    "\n",
    " 1. The first item of the output is processed from the first and second columns of x\n",
    " 2. Second item processed from second and third.\n",
    " 3. Third item processed from third and fourth.\n",
    "\n",
    "This is because the default `stride` value of `Conv1d()` is set equal to 1. `kernel_size` determines the size of the window that passes over the tensor. `stride` controls how the window passes over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [5., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7714,  0.5262, -1.1811]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again only the first value has changed. But now let's change numbers in the second column of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [1., 2.5, 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3249, -1.0543, -1.1811]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first and second values are different. Since both the first and second values are dependent on values in the second column of x (i.e., the kernel for the first and second outputs both include the second column) this makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3605, -1.1029]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = torch.nn.Conv1d(in_channels = 3, out_channels = 1, kernel_size = 2, stride =2)\n",
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that changing stride affects the size of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., -2., 3., -4.],\n",
    "                  [1., 2.5, 3., -4.],\n",
    "                  [1., -2., 3., -4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8500, -1.1029]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first output value depends on x's first and second columns' values, and second output depends on x's third and fourth columns' values. So changing the second column's values only affects the first output value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolutions\n",
    "\n",
    "So wait a minute...a 1D convolution can still \"handle\" a 2-dimensional input or even higher. The \"1D\" in 1D convolutions doesn't refer to the the 1D size of the input, but the 1D size of the kernel.\n",
    "\n",
    "Let's try everything again with `Conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the tensor is now 3D instead of 2D.\n",
    "x = torch.tensor([[[1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this won't work! in_channels has to equal 1, the first dimension of torch.Size. Think of this as a grayscale image. in_channels = 3 for RGB images. \n",
    "# conv = torch.nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4544,  0.1782, -0.3812],\n",
       "         [-0.4544,  0.1782, -0.3812]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's change `out_channels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 2, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3264, -1.3071,  1.2338],\n",
       "         [ 0.3264, -1.3071,  1.2338]],\n",
       "\n",
       "        [[-2.5867,  3.1263, -5.6091],\n",
       "         [-2.5867,  3.1263, -5.6091]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Size Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8332, -1.8079],\n",
       "         [ 0.8332, -1.8079]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.0874,  3.9895]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the risk of confusing things, you can say that a Conv1D for a 2D tensor of size (R,C) with `kernel_size` = X is the same as a Conv2D where `kernel_size` = (R,X) for a 3D tensor of size (1, R, C) for any value of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = (3,3), stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1528]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when the kernel \"window goes outside the tensor\" it doesn't break, but just doesn't return any values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the tensor is now 3D instead of 2D.\n",
    "x = torch.tensor([[[1., -2., 3.],\n",
    "                  [1., -2., 3.],\n",
    "                  [1., -2., 3.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1528]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the (3,3) kernel, this means that the fourth column's values essentially don't matter to the output of the 2D convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Changed\n",
    "\n",
    "Start with original tensor and a (3,3) kernel convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the tensor is now 3D instead of 2D.\n",
    "x = torch.tensor([[[1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.],\n",
    "                  [1., -2., 3., -4.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1778,  1.4444]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change padding from 0 to 1. This adds 1 extra cell on the \"border\" of the tensor. Each cell is filled with value of 0 (`padding_mode='zeros'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6122,  0.3091, -1.0344, -0.1838],\n",
       "         [-1.5994,  2.0282, -3.4853,  1.3570],\n",
       "         [-1.2327,  1.2924, -2.3804,  1.4826]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n",
    "\n",
    "Start with original tensor and a (2,2) kernel convolution\n",
    "\n",
    "NOTE: Default `dilation=1` not 0!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3712, 0.1740, 0.8732],\n",
       "         [0.3712, 0.1740, 0.8732]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 2, dilation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5879,  2.2657]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Dilated convolution animations\" in https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md for visualization of dilations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0818, 0.4904, 0.4396,  ..., 0.4680, 0.8515, 0.0315],\n",
       "          [0.5161, 0.1898, 0.1071,  ..., 0.5365, 0.3878, 0.4639],\n",
       "          [0.5068, 0.1542, 0.0896,  ..., 0.9905, 0.2112, 0.9695],\n",
       "          ...,\n",
       "          [0.0776, 0.8803, 0.5560,  ..., 0.2348, 0.4752, 0.4588],\n",
       "          [0.3031, 0.8303, 0.3840,  ..., 0.3982, 0.7655, 0.1367],\n",
       "          [0.3387, 0.1670, 0.6451,  ..., 0.0214, 0.0660, 0.8802]],\n",
       "\n",
       "         [[0.5049, 0.8821, 0.1494,  ..., 0.7429, 0.2653, 0.2950],\n",
       "          [0.7912, 0.3819, 0.9304,  ..., 0.9779, 0.7207, 0.4330],\n",
       "          [0.2216, 0.2942, 0.8489,  ..., 0.0421, 0.3582, 0.2067],\n",
       "          ...,\n",
       "          [0.9594, 0.0447, 0.9619,  ..., 0.8767, 0.0074, 0.8242],\n",
       "          [0.7905, 0.8473, 0.0883,  ..., 0.2907, 0.7714, 0.2771],\n",
       "          [0.0093, 0.2354, 0.2970,  ..., 0.1223, 0.2246, 0.1411]],\n",
       "\n",
       "         [[0.3732, 0.9797, 0.6755,  ..., 0.7781, 0.2280, 0.8960],\n",
       "          [0.0426, 0.2522, 0.8018,  ..., 0.8708, 0.7406, 0.9082],\n",
       "          [0.6908, 0.2624, 0.2060,  ..., 0.1871, 0.6210, 0.8070],\n",
       "          ...,\n",
       "          [0.4154, 0.0729, 0.2739,  ..., 0.9469, 0.0391, 0.6654],\n",
       "          [0.7037, 0.2677, 0.2140,  ..., 0.7587, 0.6024, 0.0793],\n",
       "          [0.4355, 0.5644, 0.5010,  ..., 0.4141, 0.5243, 0.1731]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.1159, 0.9497, 0.1583,  ..., 0.5274, 0.1921, 0.8585],\n",
       "          [0.3172, 0.3023, 0.0382,  ..., 0.0996, 0.7354, 0.0668],\n",
       "          [0.1908, 0.3764, 0.2348,  ..., 0.4903, 0.6293, 0.0951],\n",
       "          ...,\n",
       "          [0.2470, 0.0372, 0.1399,  ..., 0.6884, 0.8098, 0.1232],\n",
       "          [0.3119, 0.1467, 0.6879,  ..., 0.2689, 0.8867, 0.7989],\n",
       "          [0.3924, 0.6151, 0.5163,  ..., 0.6965, 0.0656, 0.6391]],\n",
       "\n",
       "         [[0.6383, 0.5576, 0.9712,  ..., 0.6923, 0.7802, 0.6657],\n",
       "          [0.9636, 0.9401, 0.9031,  ..., 0.7448, 0.7764, 0.7057],\n",
       "          [0.2151, 0.9433, 0.1651,  ..., 0.2579, 0.3347, 0.6272],\n",
       "          ...,\n",
       "          [0.0972, 0.6619, 0.3188,  ..., 0.2380, 0.0159, 0.7211],\n",
       "          [0.8228, 0.9034, 0.3261,  ..., 0.7780, 0.6041, 0.7456],\n",
       "          [0.8580, 0.1503, 0.8018,  ..., 0.2623, 0.6317, 0.6186]],\n",
       "\n",
       "         [[0.8432, 0.7603, 0.4611,  ..., 0.7365, 0.5249, 0.2849],\n",
       "          [0.2986, 0.2889, 0.0464,  ..., 0.0050, 0.7483, 0.0366],\n",
       "          [0.1592, 0.9918, 0.3688,  ..., 0.6021, 0.9353, 0.4427],\n",
       "          ...,\n",
       "          [0.4430, 0.5259, 0.8200,  ..., 0.4153, 0.2962, 0.9044],\n",
       "          [0.0883, 0.7976, 0.1660,  ..., 0.0554, 0.3244, 0.0116],\n",
       "          [0.3585, 0.5080, 0.5127,  ..., 0.8191, 0.0494, 0.1702]]],\n",
       "\n",
       "\n",
       "        [[[0.8748, 0.7644, 0.4034,  ..., 0.2276, 0.4014, 0.5381],\n",
       "          [0.7209, 0.3750, 0.8922,  ..., 0.3022, 0.9574, 0.8427],\n",
       "          [0.0014, 0.4499, 0.7251,  ..., 0.8993, 0.4446, 0.5779],\n",
       "          ...,\n",
       "          [0.0949, 0.9578, 0.2617,  ..., 0.7937, 0.7444, 0.8448],\n",
       "          [0.5259, 0.7738, 0.5045,  ..., 0.9859, 0.3590, 0.6911],\n",
       "          [0.3890, 0.4657, 0.6654,  ..., 0.2981, 0.9433, 0.6930]],\n",
       "\n",
       "         [[0.4471, 0.4595, 0.2695,  ..., 0.8304, 0.0806, 0.4271],\n",
       "          [0.4964, 0.3322, 0.6244,  ..., 0.1003, 0.7379, 0.3970],\n",
       "          [0.3187, 0.3748, 0.8088,  ..., 0.6173, 0.3245, 0.8488],\n",
       "          ...,\n",
       "          [0.2717, 0.8258, 0.0330,  ..., 0.0985, 0.6173, 0.9583],\n",
       "          [0.5828, 0.6924, 0.1027,  ..., 0.0573, 0.2188, 0.5261],\n",
       "          [0.5840, 0.3688, 0.3934,  ..., 0.5606, 0.0611, 0.6139]],\n",
       "\n",
       "         [[0.0855, 0.8810, 0.0260,  ..., 0.9981, 0.3090, 0.6815],\n",
       "          [0.6521, 0.1249, 0.8275,  ..., 0.6063, 0.3775, 0.8569],\n",
       "          [0.8617, 0.2516, 0.5152,  ..., 0.8371, 0.6027, 0.9689],\n",
       "          ...,\n",
       "          [0.2618, 0.7835, 0.1991,  ..., 0.4520, 0.3989, 0.7023],\n",
       "          [0.7938, 0.4789, 0.8758,  ..., 0.0811, 0.4029, 0.4134],\n",
       "          [0.1167, 0.5593, 0.0182,  ..., 0.5978, 0.5295, 0.6604]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7862, 0.1776, 0.1294,  ..., 0.8106, 0.1402, 0.3817],\n",
       "          [0.5268, 0.9495, 0.0442,  ..., 0.5374, 0.0432, 0.0376],\n",
       "          [0.6706, 0.3582, 0.3161,  ..., 0.5304, 0.1605, 0.5029],\n",
       "          ...,\n",
       "          [0.8486, 0.4957, 0.8414,  ..., 0.3343, 0.7555, 0.2329],\n",
       "          [0.9693, 0.2103, 0.2751,  ..., 0.6537, 0.5432, 0.5202],\n",
       "          [0.6896, 0.8513, 0.5273,  ..., 0.2972, 0.2788, 0.0747]],\n",
       "\n",
       "         [[0.9808, 0.4937, 0.6140,  ..., 0.9253, 0.2414, 0.8702],\n",
       "          [0.9393, 0.0385, 0.8842,  ..., 0.8937, 0.4243, 0.6110],\n",
       "          [0.9044, 0.3693, 0.2548,  ..., 0.2387, 0.2947, 0.0683],\n",
       "          ...,\n",
       "          [0.3826, 0.5488, 0.2917,  ..., 0.9381, 0.6869, 0.0223],\n",
       "          [0.6177, 0.1286, 0.0594,  ..., 0.0210, 0.1568, 0.3599],\n",
       "          [0.6592, 0.1706, 0.5957,  ..., 0.8675, 0.5977, 0.0632]],\n",
       "\n",
       "         [[0.2781, 0.7402, 0.6175,  ..., 0.6329, 0.7676, 0.3855],\n",
       "          [0.8480, 0.7054, 0.9628,  ..., 0.2473, 0.7649, 0.3817],\n",
       "          [0.1600, 0.2341, 0.8538,  ..., 0.3776, 0.6853, 0.2349],\n",
       "          ...,\n",
       "          [0.7119, 0.1336, 0.1651,  ..., 0.6193, 0.9853, 0.3267],\n",
       "          [0.0267, 0.5196, 0.2623,  ..., 0.6598, 0.5832, 0.3987],\n",
       "          [0.2611, 0.5292, 0.4079,  ..., 0.4972, 0.4401, 0.3653]]],\n",
       "\n",
       "\n",
       "        [[[0.9205, 0.8875, 0.6490,  ..., 0.2762, 0.4978, 0.0994],\n",
       "          [0.3866, 0.2168, 0.3601,  ..., 0.7178, 0.0234, 0.2834],\n",
       "          [0.8824, 0.7034, 0.0502,  ..., 0.5496, 0.6593, 0.6521],\n",
       "          ...,\n",
       "          [0.7771, 0.5965, 0.4675,  ..., 0.8608, 0.2101, 0.7604],\n",
       "          [0.0304, 0.7535, 0.9874,  ..., 0.2315, 0.9193, 0.3956],\n",
       "          [0.7917, 0.6700, 0.6516,  ..., 0.6187, 0.9872, 0.5677]],\n",
       "\n",
       "         [[0.3240, 0.4903, 0.8595,  ..., 0.1119, 0.4942, 0.7684],\n",
       "          [0.7041, 0.1756, 0.2860,  ..., 0.5555, 0.0071, 0.0751],\n",
       "          [0.2693, 0.3640, 0.0272,  ..., 0.7798, 0.6478, 0.0107],\n",
       "          ...,\n",
       "          [0.0522, 0.2186, 0.0727,  ..., 0.5506, 0.9367, 0.1873],\n",
       "          [0.0360, 0.1415, 0.1319,  ..., 0.6287, 0.9176, 0.3983],\n",
       "          [0.5226, 0.9691, 0.1163,  ..., 0.4053, 0.8531, 0.5705]],\n",
       "\n",
       "         [[0.6756, 0.1953, 0.2950,  ..., 0.6225, 0.4477, 0.7168],\n",
       "          [0.4187, 0.8240, 0.4827,  ..., 0.0517, 0.6045, 0.4118],\n",
       "          [0.8576, 0.8271, 0.9721,  ..., 0.3888, 0.8685, 0.6664],\n",
       "          ...,\n",
       "          [0.1569, 0.7332, 0.5831,  ..., 0.8337, 0.4510, 0.1724],\n",
       "          [0.1186, 0.4130, 0.0440,  ..., 0.3961, 0.1113, 0.2906],\n",
       "          [0.7680, 0.3695, 0.3666,  ..., 0.2988, 0.8947, 0.1341]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0204, 0.3340, 0.1812,  ..., 0.6729, 0.9270, 0.9619],\n",
       "          [0.4748, 0.1520, 0.4738,  ..., 0.1637, 0.8347, 0.8231],\n",
       "          [0.4422, 0.8772, 0.0585,  ..., 0.0531, 0.1445, 0.1277],\n",
       "          ...,\n",
       "          [0.7596, 0.5819, 0.0164,  ..., 0.9257, 0.4673, 0.8151],\n",
       "          [0.5999, 0.4570, 0.9271,  ..., 0.9867, 0.6851, 0.2720],\n",
       "          [0.4179, 0.1527, 0.8150,  ..., 0.7532, 0.4329, 0.4839]],\n",
       "\n",
       "         [[0.0572, 0.3841, 0.9851,  ..., 0.5750, 0.1921, 0.0606],\n",
       "          [0.8564, 0.0528, 0.2176,  ..., 0.5714, 0.9845, 0.2057],\n",
       "          [0.4921, 0.6701, 0.3912,  ..., 0.2665, 0.3178, 0.4836],\n",
       "          ...,\n",
       "          [0.7061, 0.2439, 0.2220,  ..., 0.2845, 0.7167, 0.0528],\n",
       "          [0.0293, 0.7214, 0.8618,  ..., 0.6440, 0.5641, 0.7942],\n",
       "          [0.3056, 0.7999, 0.2734,  ..., 0.0506, 0.6503, 0.3202]],\n",
       "\n",
       "         [[0.0329, 0.5097, 0.0825,  ..., 0.7137, 0.6843, 0.1776],\n",
       "          [0.6192, 0.5625, 0.0055,  ..., 0.5738, 0.3840, 0.7411],\n",
       "          [0.6838, 0.5683, 0.7636,  ..., 0.2753, 0.5031, 0.2776],\n",
       "          ...,\n",
       "          [0.5607, 0.3004, 0.8283,  ..., 0.0761, 0.0566, 0.2065],\n",
       "          [0.8150, 0.4851, 0.1901,  ..., 0.6599, 0.9420, 0.6594],\n",
       "          [0.8060, 0.2909, 0.2614,  ..., 0.0821, 0.5381, 0.9060]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.8754, 0.1375, 0.4001,  ..., 0.1756, 0.8778, 0.0935],\n",
       "          [0.2486, 0.4323, 0.6385,  ..., 0.5530, 0.2065, 0.9529],\n",
       "          [0.1981, 0.3951, 0.2794,  ..., 0.2939, 0.8531, 0.3970],\n",
       "          ...,\n",
       "          [0.4222, 0.0246, 0.3363,  ..., 0.2836, 0.1663, 0.4790],\n",
       "          [0.5308, 0.2402, 0.6770,  ..., 0.9841, 0.9985, 0.2833],\n",
       "          [0.2046, 0.8586, 0.1582,  ..., 0.2000, 0.1992, 0.3492]],\n",
       "\n",
       "         [[0.8563, 0.9326, 0.6133,  ..., 0.6392, 0.7008, 0.6693],\n",
       "          [0.8342, 0.2163, 0.9324,  ..., 0.3320, 0.3992, 0.8388],\n",
       "          [0.3052, 0.7008, 0.6980,  ..., 0.6270, 0.5703, 0.7672],\n",
       "          ...,\n",
       "          [0.8272, 0.8529, 0.0611,  ..., 0.8439, 0.4124, 0.2982],\n",
       "          [0.1008, 0.9347, 0.7934,  ..., 0.8830, 0.9541, 0.6793],\n",
       "          [0.5266, 0.5874, 0.7719,  ..., 0.8667, 0.2685, 0.1512]],\n",
       "\n",
       "         [[0.9671, 0.2210, 0.0965,  ..., 0.5391, 0.8634, 0.2841],\n",
       "          [0.3832, 0.3112, 0.0888,  ..., 0.8078, 0.8868, 0.2643],\n",
       "          [0.9787, 0.0110, 0.6455,  ..., 0.3876, 0.0574, 0.1073],\n",
       "          ...,\n",
       "          [0.6535, 0.6183, 0.9321,  ..., 0.1803, 0.0515, 0.2280],\n",
       "          [0.4678, 0.2357, 0.5622,  ..., 0.9106, 0.2395, 0.4524],\n",
       "          [0.5413, 0.2428, 0.0980,  ..., 0.7800, 0.0238, 0.8989]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.8842, 0.6478, 0.5598,  ..., 0.9524, 0.4590, 0.3893],\n",
       "          [0.9149, 0.5739, 0.0202,  ..., 0.0718, 0.5830, 0.9983],\n",
       "          [0.8252, 0.5722, 0.5182,  ..., 0.3833, 0.8463, 0.6347],\n",
       "          ...,\n",
       "          [0.8768, 0.3594, 0.4279,  ..., 0.2289, 0.3614, 0.8388],\n",
       "          [0.2457, 0.4630, 0.6017,  ..., 0.3754, 0.8871, 0.2319],\n",
       "          [0.7303, 0.7196, 0.5511,  ..., 0.3793, 0.1548, 0.9448]],\n",
       "\n",
       "         [[0.6761, 0.7317, 0.3722,  ..., 0.0204, 0.9478, 0.3776],\n",
       "          [0.9027, 0.0122, 0.6386,  ..., 0.6491, 0.7100, 0.4679],\n",
       "          [0.2776, 0.9011, 0.5874,  ..., 0.3558, 0.9416, 0.8317],\n",
       "          ...,\n",
       "          [0.1329, 0.1218, 0.7435,  ..., 0.7217, 0.7909, 0.6686],\n",
       "          [0.2656, 0.6531, 0.2926,  ..., 0.6306, 0.4673, 0.9750],\n",
       "          [0.9586, 0.2303, 0.6805,  ..., 0.3984, 0.3653, 0.7751]],\n",
       "\n",
       "         [[0.1975, 0.1608, 0.0745,  ..., 0.4734, 0.0849, 0.7020],\n",
       "          [0.9297, 0.8649, 0.2731,  ..., 0.5674, 0.8500, 0.4516],\n",
       "          [0.4725, 0.4390, 0.8547,  ..., 0.0986, 0.9595, 0.5249],\n",
       "          ...,\n",
       "          [0.9242, 0.6133, 0.4425,  ..., 0.1102, 0.8023, 0.7917],\n",
       "          [0.1469, 0.6308, 0.9908,  ..., 0.3044, 0.7519, 0.1077],\n",
       "          [0.8045, 0.6515, 0.8525,  ..., 0.4449, 0.4416, 0.3439]]],\n",
       "\n",
       "\n",
       "        [[[0.9705, 0.3570, 0.6549,  ..., 0.0189, 0.8787, 0.6658],\n",
       "          [0.4308, 0.3936, 0.3260,  ..., 0.7711, 0.8947, 0.1728],\n",
       "          [0.2918, 0.0724, 0.7755,  ..., 0.7631, 0.1397, 0.0980],\n",
       "          ...,\n",
       "          [0.5070, 0.4658, 0.0326,  ..., 0.3926, 0.3470, 0.1833],\n",
       "          [0.2557, 0.9480, 0.9220,  ..., 0.3528, 0.7173, 0.7856],\n",
       "          [0.0233, 0.8096, 0.6204,  ..., 0.3037, 0.1093, 0.2491]],\n",
       "\n",
       "         [[0.9591, 0.0725, 0.0185,  ..., 0.2095, 0.3026, 0.1277],\n",
       "          [0.7484, 0.8913, 0.1220,  ..., 0.9927, 0.6089, 0.3795],\n",
       "          [0.7827, 0.1876, 0.4876,  ..., 0.9508, 0.9579, 0.4803],\n",
       "          ...,\n",
       "          [0.0795, 0.1645, 0.4953,  ..., 0.2535, 0.0103, 0.8734],\n",
       "          [0.6786, 0.4137, 0.8285,  ..., 0.1486, 0.7082, 0.0627],\n",
       "          [0.6672, 0.4984, 0.3839,  ..., 0.0875, 0.9076, 0.1358]],\n",
       "\n",
       "         [[0.0768, 0.5394, 0.6001,  ..., 0.7199, 0.1247, 0.3352],\n",
       "          [0.6076, 0.4892, 0.2404,  ..., 0.1437, 0.4402, 0.9635],\n",
       "          [0.7400, 0.1102, 0.2692,  ..., 0.6650, 0.8596, 0.4046],\n",
       "          ...,\n",
       "          [0.3619, 0.6289, 0.1167,  ..., 0.0201, 0.4530, 0.9839],\n",
       "          [0.4571, 0.7383, 0.1776,  ..., 0.2910, 0.0484, 0.3345],\n",
       "          [0.1288, 0.2548, 0.4773,  ..., 0.7024, 0.9939, 0.4691]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7630, 0.4982, 0.7950,  ..., 0.1557, 0.4942, 0.7833],\n",
       "          [0.7846, 0.3239, 0.9665,  ..., 0.5069, 0.1329, 0.3640],\n",
       "          [0.9186, 0.1594, 0.9776,  ..., 0.8390, 0.0129, 0.0517],\n",
       "          ...,\n",
       "          [0.9216, 0.6435, 0.2448,  ..., 0.6523, 0.0781, 0.5820],\n",
       "          [0.1720, 0.3741, 0.9861,  ..., 0.7678, 0.0417, 0.8825],\n",
       "          [0.4345, 0.5818, 0.9585,  ..., 0.1777, 0.2882, 0.5000]],\n",
       "\n",
       "         [[0.5210, 0.7464, 0.4233,  ..., 0.0557, 0.2414, 0.0030],\n",
       "          [0.4239, 0.5303, 0.6248,  ..., 0.5144, 0.7911, 0.1509],\n",
       "          [0.6462, 0.1638, 0.0067,  ..., 0.9162, 0.7233, 0.1851],\n",
       "          ...,\n",
       "          [0.4158, 0.3320, 0.9501,  ..., 0.5748, 0.5860, 0.0322],\n",
       "          [0.1192, 0.5832, 0.0782,  ..., 0.7909, 0.9676, 0.4344],\n",
       "          [0.9278, 0.2104, 0.9020,  ..., 0.6205, 0.9309, 0.4370]],\n",
       "\n",
       "         [[0.1216, 0.0693, 0.8151,  ..., 0.9757, 0.4467, 0.8620],\n",
       "          [0.7529, 0.9411, 0.2248,  ..., 0.9603, 0.9383, 0.9169],\n",
       "          [0.1535, 0.2237, 0.7775,  ..., 0.7947, 0.5984, 0.4092],\n",
       "          ...,\n",
       "          [0.5739, 0.9374, 0.6758,  ..., 0.8000, 0.4203, 0.1824],\n",
       "          [0.3487, 0.4376, 0.8193,  ..., 0.6982, 0.2965, 0.8961],\n",
       "          [0.7782, 0.8213, 0.5158,  ..., 0.3660, 0.6793, 0.4024]]],\n",
       "\n",
       "\n",
       "        [[[0.7360, 0.9262, 0.9922,  ..., 0.5279, 0.7083, 0.6151],\n",
       "          [0.0257, 0.4595, 0.7426,  ..., 0.5533, 0.0583, 0.1066],\n",
       "          [0.5688, 0.6602, 0.9221,  ..., 0.0750, 0.8141, 0.8690],\n",
       "          ...,\n",
       "          [0.0286, 0.2621, 0.3889,  ..., 0.1284, 0.6888, 0.6969],\n",
       "          [0.0488, 0.7926, 0.8446,  ..., 0.6939, 0.7164, 0.9802],\n",
       "          [0.7302, 0.5331, 0.1678,  ..., 0.1711, 0.2558, 0.7141]],\n",
       "\n",
       "         [[0.5293, 0.6303, 0.6255,  ..., 0.3474, 0.2117, 0.1968],\n",
       "          [0.0806, 0.2136, 0.2470,  ..., 0.2391, 0.1226, 0.7004],\n",
       "          [0.1137, 0.7985, 0.5207,  ..., 0.5002, 0.5360, 0.3536],\n",
       "          ...,\n",
       "          [0.5811, 0.1516, 0.7656,  ..., 0.2279, 0.5254, 0.3282],\n",
       "          [0.2803, 0.4630, 0.2643,  ..., 0.9436, 0.8054, 0.3534],\n",
       "          [0.4072, 0.2530, 0.2343,  ..., 0.9372, 0.1910, 0.4853]],\n",
       "\n",
       "         [[0.7134, 0.9147, 0.3046,  ..., 0.0527, 0.0914, 0.2261],\n",
       "          [0.0497, 0.6262, 0.2234,  ..., 0.5220, 0.9965, 0.3060],\n",
       "          [0.9496, 0.2943, 0.6860,  ..., 0.0700, 0.4681, 0.0351],\n",
       "          ...,\n",
       "          [0.5549, 0.6032, 0.8523,  ..., 0.6923, 0.5441, 0.8175],\n",
       "          [0.5302, 0.7674, 0.9914,  ..., 0.8736, 0.2051, 0.0428],\n",
       "          [0.3143, 0.4500, 0.9012,  ..., 0.1546, 0.2203, 0.4704]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7945, 0.9533, 0.8768,  ..., 0.4545, 0.4583, 0.6044],\n",
       "          [0.8869, 0.8367, 0.7707,  ..., 0.9118, 0.1728, 0.8218],\n",
       "          [0.2862, 0.9205, 0.8559,  ..., 0.4276, 0.1829, 0.8427],\n",
       "          ...,\n",
       "          [0.8624, 0.9609, 0.2945,  ..., 0.0367, 0.9813, 0.8891],\n",
       "          [0.1756, 0.1210, 0.8062,  ..., 0.0614, 0.8181, 0.4308],\n",
       "          [0.2226, 0.7333, 0.1769,  ..., 0.8477, 0.3292, 0.0790]],\n",
       "\n",
       "         [[0.3319, 0.1287, 0.9803,  ..., 0.3496, 0.8574, 0.8002],\n",
       "          [0.3994, 0.1250, 0.3340,  ..., 0.1370, 0.4443, 0.4357],\n",
       "          [0.9563, 0.2274, 0.6608,  ..., 0.0730, 0.0843, 0.5615],\n",
       "          ...,\n",
       "          [0.9696, 0.8641, 0.3460,  ..., 0.4861, 0.0053, 0.7898],\n",
       "          [0.3487, 0.9040, 0.2191,  ..., 0.0116, 0.6507, 0.8876],\n",
       "          [0.3549, 0.8689, 0.3843,  ..., 0.6882, 0.2679, 0.5462]],\n",
       "\n",
       "         [[0.3861, 0.4956, 0.3900,  ..., 0.0020, 0.9318, 0.4667],\n",
       "          [0.9633, 0.0558, 0.1381,  ..., 0.0122, 0.1228, 0.2087],\n",
       "          [0.0588, 0.5101, 0.0017,  ..., 0.1954, 0.7613, 0.2829],\n",
       "          ...,\n",
       "          [0.5316, 0.6913, 0.7016,  ..., 0.8529, 0.4465, 0.1797],\n",
       "          [0.2696, 0.4419, 0.4592,  ..., 0.0820, 0.0801, 0.9034],\n",
       "          [0.7611, 0.2752, 0.4864,  ..., 0.5366, 0.8409, 0.5496]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((7,100,100,100))\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 100, 100, 100])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(N, C, D, H, W) = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 30, 30, 30])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=13, stride=3)\n",
    "conv(x).shape # 0.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Shape section in: https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_out = ((D + 2*padding - dilation*(kernel_size-1) - 1)/stride) + 1\n",
    "# H_out = ((H + 2*padding - dilation*(kernel_size-1) - 1)/stride) + 1\n",
    "# W_out = ((W + 2*padding - dilation*(kernel_size-1) - 1)/stride) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = 500\n",
    "\n",
    "# padding = 0\n",
    "# dilation = 1\n",
    "# stride = 16\n",
    "\n",
    "# kernel_size = 260\n",
    "\n",
    "# D_out = ((D + 2*padding - dilation*(kernel_size-1) - 1)/stride) + 1\n",
    "\n",
    "# D_out = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 30\n",
    "D_out = 16\n",
    "padding = 0\n",
    "dilation = 1\n",
    "stride = 1\n",
    "\n",
    "kernel_size = (((D_out - 1)*stride - D + 1 - 2*padding)/(-dilation)) + 1\n",
    "\n",
    "kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 64\n",
    "D_out = 4\n",
    "padding = 0\n",
    "dilation = 1\n",
    "stride = 1\n",
    "\n",
    "kernel_size = (((D_out - 1)*stride - D + 1 - 2*padding)/(-dilation)) + 1\n",
    "\n",
    "kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 4\n",
    "D_out = 1\n",
    "padding = 0\n",
    "dilation = 1\n",
    "stride = 1\n",
    "\n",
    "kernel_size = (((D_out - 1)*stride - D + 1 - 2*padding)/(-dilation)) + 1\n",
    "\n",
    "kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 91, 91, 91])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=10)\n",
    "conv(x).shape # 0.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 51, 51, 51])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=50)\n",
    "conv(x).shape # 22.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10, 10])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=10, stride=10)\n",
    "conv(x).shape # 0.0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Input Tensor\n",
    "\n",
    "Note that code has been commented out because of their long runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((7,500,500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 500, 500, 500])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(N, C, D, H, W) = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[2.1682e-01, 2.7437e-01, 1.8413e-01,  ..., 4.7576e-01,\n",
       "            7.7705e-01, 9.4222e-01],\n",
       "           [3.5114e-01, 7.6827e-01, 3.8245e-01,  ..., 1.6009e-01,\n",
       "            7.4513e-01, 6.5597e-01],\n",
       "           [8.8064e-02, 5.6033e-01, 7.2631e-01,  ..., 9.2605e-01,\n",
       "            9.8774e-01, 7.3875e-01],\n",
       "           ...,\n",
       "           [2.0674e-01, 8.2565e-01, 6.5862e-01,  ..., 3.3292e-01,\n",
       "            8.5015e-01, 9.0070e-02],\n",
       "           [2.6910e-01, 1.4809e-01, 9.9401e-01,  ..., 5.9758e-02,\n",
       "            8.9558e-01, 1.9362e-01],\n",
       "           [3.0928e-01, 5.6732e-01, 9.2520e-01,  ..., 1.6263e-01,\n",
       "            3.9213e-01, 1.8143e-01]],\n",
       "\n",
       "          [[1.8359e-01, 6.5399e-01, 8.9489e-01,  ..., 7.0362e-01,\n",
       "            9.7558e-01, 7.1768e-01],\n",
       "           [8.4069e-01, 7.4144e-02, 7.4055e-01,  ..., 9.1524e-01,\n",
       "            5.7750e-01, 7.3845e-01],\n",
       "           [4.7890e-02, 6.3678e-01, 1.6458e-01,  ..., 5.5144e-01,\n",
       "            6.9017e-01, 9.6967e-01],\n",
       "           ...,\n",
       "           [9.2121e-01, 8.7819e-01, 9.0473e-01,  ..., 2.6081e-01,\n",
       "            5.9056e-01, 7.6233e-01],\n",
       "           [4.7123e-02, 5.4793e-01, 4.0362e-01,  ..., 5.5703e-01,\n",
       "            5.5536e-01, 1.7077e-01],\n",
       "           [5.9546e-01, 5.9731e-02, 8.5954e-01,  ..., 4.4334e-01,\n",
       "            4.9329e-01, 6.3598e-01]],\n",
       "\n",
       "          [[1.9606e-01, 5.6526e-01, 2.9544e-01,  ..., 3.8069e-02,\n",
       "            5.2088e-01, 1.9501e-01],\n",
       "           [9.8740e-01, 3.7116e-01, 2.8790e-01,  ..., 8.5790e-01,\n",
       "            5.4203e-01, 6.6584e-02],\n",
       "           [6.8110e-01, 4.3444e-01, 7.1028e-01,  ..., 3.8540e-01,\n",
       "            9.2370e-01, 4.4213e-01],\n",
       "           ...,\n",
       "           [7.9151e-01, 7.9113e-01, 5.4977e-02,  ..., 1.7958e-01,\n",
       "            2.8559e-01, 4.4552e-01],\n",
       "           [1.3892e-01, 4.4415e-01, 5.5492e-01,  ..., 1.5641e-01,\n",
       "            9.0514e-01, 1.7960e-01],\n",
       "           [3.0101e-01, 1.6444e-02, 8.2580e-01,  ..., 2.0901e-01,\n",
       "            9.8483e-01, 3.9189e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[8.7709e-01, 5.8948e-01, 9.8054e-01,  ..., 3.7828e-01,\n",
       "            1.4470e-01, 2.3067e-01],\n",
       "           [3.7311e-01, 9.8145e-01, 3.0258e-01,  ..., 9.0412e-01,\n",
       "            5.2445e-01, 8.7444e-01],\n",
       "           [3.4263e-01, 5.7506e-03, 7.0657e-01,  ..., 5.8324e-02,\n",
       "            9.8559e-01, 9.2391e-02],\n",
       "           ...,\n",
       "           [3.0853e-01, 1.9481e-01, 9.0858e-01,  ..., 5.3073e-02,\n",
       "            6.2958e-01, 6.3506e-01],\n",
       "           [7.6009e-01, 2.6633e-02, 3.4401e-01,  ..., 4.9660e-01,\n",
       "            8.5811e-01, 3.6817e-01],\n",
       "           [8.6416e-01, 4.9638e-01, 6.8487e-01,  ..., 8.8467e-02,\n",
       "            4.9684e-01, 2.9902e-01]],\n",
       "\n",
       "          [[6.4369e-01, 4.5403e-01, 8.4320e-01,  ..., 6.9722e-02,\n",
       "            7.8708e-01, 7.4046e-01],\n",
       "           [4.7546e-01, 2.0630e-01, 3.2305e-01,  ..., 9.8200e-01,\n",
       "            7.2729e-01, 1.5044e-01],\n",
       "           [7.7157e-01, 2.0847e-01, 4.2026e-01,  ..., 3.6058e-02,\n",
       "            5.2240e-02, 4.9281e-01],\n",
       "           ...,\n",
       "           [2.0724e-01, 5.7817e-01, 6.2809e-01,  ..., 2.8447e-01,\n",
       "            2.4223e-01, 5.4036e-01],\n",
       "           [6.5860e-01, 6.7336e-01, 1.2688e-01,  ..., 1.1968e-01,\n",
       "            3.6230e-02, 2.1502e-02],\n",
       "           [3.8300e-01, 5.1730e-01, 1.4701e-01,  ..., 7.1273e-01,\n",
       "            9.5273e-01, 6.5176e-01]],\n",
       "\n",
       "          [[6.4723e-01, 9.9587e-01, 2.3690e-01,  ..., 8.7993e-01,\n",
       "            1.8052e-01, 6.5703e-01],\n",
       "           [3.9708e-01, 4.2447e-01, 1.0022e-01,  ..., 5.9201e-01,\n",
       "            3.5113e-01, 7.5253e-01],\n",
       "           [3.9807e-01, 8.6282e-01, 4.8220e-01,  ..., 9.9774e-01,\n",
       "            5.0528e-02, 4.1480e-01],\n",
       "           ...,\n",
       "           [8.7483e-01, 6.7354e-01, 9.4318e-01,  ..., 7.8995e-02,\n",
       "            2.2330e-01, 5.4254e-01],\n",
       "           [7.7634e-01, 1.6542e-01, 2.3095e-01,  ..., 5.9276e-01,\n",
       "            4.8893e-01, 2.5631e-01],\n",
       "           [5.5522e-01, 9.9877e-01, 2.5342e-01,  ..., 5.1557e-02,\n",
       "            1.1914e-01, 1.8804e-02]]],\n",
       "\n",
       "\n",
       "         [[[6.4823e-01, 5.7551e-01, 3.3944e-01,  ..., 3.9511e-01,\n",
       "            9.1206e-01, 3.7278e-01],\n",
       "           [2.9717e-01, 8.5637e-01, 9.4770e-01,  ..., 2.0250e-02,\n",
       "            2.2680e-02, 1.5545e-01],\n",
       "           [9.2651e-01, 2.7538e-01, 1.9208e-01,  ..., 6.7546e-03,\n",
       "            9.7843e-02, 9.4362e-01],\n",
       "           ...,\n",
       "           [8.5222e-01, 3.0290e-01, 6.3662e-01,  ..., 9.6734e-01,\n",
       "            4.6680e-01, 8.3859e-01],\n",
       "           [6.3334e-01, 5.5334e-01, 2.0565e-01,  ..., 5.8446e-01,\n",
       "            2.4754e-01, 4.2377e-01],\n",
       "           [2.7171e-01, 6.8585e-01, 8.9339e-01,  ..., 7.0651e-01,\n",
       "            5.2389e-01, 3.6362e-01]],\n",
       "\n",
       "          [[4.1546e-02, 4.8906e-01, 6.6380e-01,  ..., 2.1315e-01,\n",
       "            7.4727e-01, 9.7144e-02],\n",
       "           [7.4927e-01, 4.4562e-01, 1.9594e-01,  ..., 5.0551e-01,\n",
       "            8.8954e-01, 6.5847e-01],\n",
       "           [7.9868e-01, 5.0243e-01, 2.0305e-01,  ..., 7.5106e-02,\n",
       "            4.9719e-01, 3.5377e-01],\n",
       "           ...,\n",
       "           [7.8842e-01, 1.1233e-01, 3.4520e-02,  ..., 1.4927e-01,\n",
       "            5.7177e-01, 5.1096e-01],\n",
       "           [3.8657e-01, 4.7755e-02, 7.4271e-01,  ..., 9.4267e-01,\n",
       "            4.3208e-01, 3.2761e-01],\n",
       "           [6.8022e-02, 7.8198e-01, 6.3966e-01,  ..., 8.6417e-01,\n",
       "            9.9163e-02, 9.8726e-01]],\n",
       "\n",
       "          [[1.6059e-01, 1.1389e-01, 9.5743e-01,  ..., 1.3425e-01,\n",
       "            9.3589e-01, 2.1739e-01],\n",
       "           [2.4710e-01, 2.5006e-01, 6.5861e-01,  ..., 4.8810e-01,\n",
       "            5.2964e-01, 6.6794e-01],\n",
       "           [4.5929e-01, 7.0441e-01, 7.2424e-01,  ..., 8.8099e-01,\n",
       "            7.7432e-01, 7.7798e-01],\n",
       "           ...,\n",
       "           [7.2990e-01, 7.0225e-01, 2.9048e-01,  ..., 3.2391e-01,\n",
       "            4.0062e-01, 3.3630e-01],\n",
       "           [9.7021e-01, 1.7816e-01, 7.8180e-01,  ..., 8.4431e-01,\n",
       "            7.3791e-01, 8.9500e-01],\n",
       "           [7.4867e-01, 4.7531e-01, 8.1336e-01,  ..., 1.6487e-01,\n",
       "            7.1282e-01, 4.6136e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[9.2521e-01, 2.3204e-01, 7.7116e-01,  ..., 2.7891e-01,\n",
       "            2.3771e-01, 2.9665e-01],\n",
       "           [4.5123e-01, 4.9076e-01, 2.9905e-01,  ..., 2.3481e-01,\n",
       "            2.5352e-01, 3.6432e-01],\n",
       "           [9.8844e-01, 4.7919e-01, 5.3887e-01,  ..., 9.6966e-01,\n",
       "            6.1665e-01, 5.6610e-01],\n",
       "           ...,\n",
       "           [3.9511e-01, 2.5822e-01, 4.0560e-01,  ..., 4.3357e-01,\n",
       "            8.4678e-01, 8.3418e-01],\n",
       "           [2.5035e-01, 3.0825e-01, 2.0091e-01,  ..., 5.8711e-01,\n",
       "            7.2927e-01, 7.4017e-01],\n",
       "           [6.1919e-01, 4.5808e-01, 2.2471e-01,  ..., 4.6474e-01,\n",
       "            5.1376e-02, 6.3618e-01]],\n",
       "\n",
       "          [[9.5135e-01, 4.9540e-01, 3.0593e-02,  ..., 4.6311e-01,\n",
       "            3.6183e-01, 6.0793e-01],\n",
       "           [9.2476e-01, 5.2452e-01, 3.4092e-01,  ..., 5.1233e-01,\n",
       "            7.9569e-01, 6.5299e-01],\n",
       "           [5.1149e-01, 2.7674e-01, 6.5575e-01,  ..., 9.3521e-01,\n",
       "            9.1225e-01, 5.3279e-01],\n",
       "           ...,\n",
       "           [4.4292e-02, 6.6335e-01, 9.8051e-01,  ..., 9.4662e-01,\n",
       "            6.2589e-01, 9.4289e-01],\n",
       "           [1.8195e-01, 5.3890e-01, 9.5997e-01,  ..., 4.9323e-01,\n",
       "            6.3105e-01, 5.1698e-01],\n",
       "           [6.8943e-01, 2.7690e-01, 3.5025e-02,  ..., 6.8470e-01,\n",
       "            9.5920e-01, 8.3047e-01]],\n",
       "\n",
       "          [[5.5134e-01, 5.9867e-01, 1.8988e-02,  ..., 9.4972e-01,\n",
       "            8.3311e-01, 4.0774e-01],\n",
       "           [2.7098e-01, 4.7424e-01, 6.3290e-01,  ..., 8.9140e-01,\n",
       "            8.9362e-01, 6.9130e-01],\n",
       "           [9.0248e-01, 5.4712e-01, 8.0679e-02,  ..., 2.5261e-03,\n",
       "            2.3905e-01, 4.4655e-01],\n",
       "           ...,\n",
       "           [8.6931e-01, 7.9369e-01, 3.4606e-01,  ..., 5.6378e-02,\n",
       "            2.5398e-01, 8.3761e-01],\n",
       "           [6.3034e-01, 5.1596e-01, 4.8862e-01,  ..., 2.8749e-01,\n",
       "            7.5244e-01, 7.2267e-01],\n",
       "           [6.1258e-01, 6.1730e-01, 7.1713e-01,  ..., 9.7925e-01,\n",
       "            5.2686e-01, 8.8410e-01]]],\n",
       "\n",
       "\n",
       "         [[[8.9790e-01, 1.7201e-02, 8.6965e-01,  ..., 5.3429e-02,\n",
       "            6.6151e-01, 6.9672e-01],\n",
       "           [9.1386e-01, 1.5064e-01, 7.9704e-01,  ..., 8.3983e-01,\n",
       "            2.9769e-01, 4.5456e-01],\n",
       "           [1.2299e-01, 9.7532e-01, 4.9872e-01,  ..., 4.6358e-01,\n",
       "            6.8565e-01, 4.4507e-01],\n",
       "           ...,\n",
       "           [2.2851e-01, 6.7262e-01, 5.2898e-01,  ..., 5.3462e-01,\n",
       "            1.3892e-01, 3.8938e-01],\n",
       "           [3.4462e-01, 1.9005e-01, 4.4462e-01,  ..., 8.2041e-01,\n",
       "            8.9233e-01, 5.8508e-01],\n",
       "           [1.6593e-01, 4.1866e-01, 7.8602e-01,  ..., 9.6614e-01,\n",
       "            4.3183e-01, 5.9177e-01]],\n",
       "\n",
       "          [[7.8990e-01, 3.1436e-02, 2.6836e-02,  ..., 4.5481e-01,\n",
       "            3.7545e-01, 9.1437e-01],\n",
       "           [9.1139e-01, 7.0582e-01, 1.5097e-01,  ..., 6.7541e-01,\n",
       "            4.6321e-03, 2.5765e-01],\n",
       "           [7.0609e-01, 5.8715e-01, 6.5587e-01,  ..., 5.2530e-01,\n",
       "            9.4578e-01, 6.3387e-01],\n",
       "           ...,\n",
       "           [6.2077e-01, 3.2470e-01, 5.7722e-02,  ..., 3.0019e-01,\n",
       "            3.9870e-01, 7.7809e-01],\n",
       "           [9.6113e-01, 6.8258e-01, 8.5798e-01,  ..., 2.0891e-01,\n",
       "            9.1982e-01, 7.3550e-01],\n",
       "           [9.1554e-01, 3.2883e-02, 2.0548e-01,  ..., 8.4463e-01,\n",
       "            3.5922e-01, 4.6345e-01]],\n",
       "\n",
       "          [[1.8438e-01, 5.1835e-01, 8.1060e-01,  ..., 5.3248e-01,\n",
       "            6.9658e-01, 2.8670e-01],\n",
       "           [2.3089e-01, 2.8673e-01, 5.2853e-01,  ..., 5.0925e-01,\n",
       "            2.6329e-01, 7.8015e-01],\n",
       "           [2.2855e-02, 3.3071e-01, 3.4232e-02,  ..., 1.2111e-01,\n",
       "            3.2125e-01, 4.5683e-01],\n",
       "           ...,\n",
       "           [2.7236e-01, 2.0004e-01, 2.0736e-01,  ..., 8.5394e-01,\n",
       "            5.8567e-01, 8.8958e-01],\n",
       "           [2.6322e-01, 4.0135e-01, 1.7285e-02,  ..., 3.5553e-01,\n",
       "            7.7331e-01, 2.0123e-01],\n",
       "           [8.7387e-02, 4.3580e-01, 2.5295e-01,  ..., 5.8770e-01,\n",
       "            4.9470e-01, 5.2608e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[2.5231e-01, 9.7213e-01, 2.1587e-01,  ..., 7.1368e-01,\n",
       "            1.1476e-01, 1.9899e-01],\n",
       "           [4.8519e-01, 6.7092e-01, 7.5742e-01,  ..., 8.6927e-01,\n",
       "            5.8710e-01, 9.2723e-01],\n",
       "           [8.2055e-01, 2.9067e-01, 9.1611e-01,  ..., 4.0000e-01,\n",
       "            2.7510e-02, 7.4502e-01],\n",
       "           ...,\n",
       "           [2.1197e-01, 6.3070e-01, 3.7931e-01,  ..., 4.4073e-01,\n",
       "            8.4190e-01, 2.0378e-01],\n",
       "           [9.1310e-03, 1.9711e-01, 4.0457e-01,  ..., 9.5305e-01,\n",
       "            7.1683e-01, 6.1073e-01],\n",
       "           [4.5344e-02, 2.5568e-02, 1.9870e-01,  ..., 9.5793e-02,\n",
       "            9.9347e-01, 9.2914e-01]],\n",
       "\n",
       "          [[5.4431e-01, 6.6367e-01, 6.6040e-01,  ..., 5.2283e-01,\n",
       "            7.2976e-01, 6.6362e-01],\n",
       "           [1.8637e-01, 3.2496e-01, 2.4851e-01,  ..., 6.3372e-01,\n",
       "            6.0648e-01, 6.4573e-01],\n",
       "           [5.3081e-01, 6.9740e-01, 6.2145e-01,  ..., 6.4751e-01,\n",
       "            3.9682e-01, 5.5748e-01],\n",
       "           ...,\n",
       "           [4.8729e-02, 7.9552e-01, 7.7108e-01,  ..., 7.9837e-01,\n",
       "            2.9908e-01, 5.6503e-01],\n",
       "           [8.4287e-02, 4.6943e-02, 4.2778e-01,  ..., 1.2603e-01,\n",
       "            1.0541e-01, 6.9054e-01],\n",
       "           [6.5292e-03, 6.6905e-03, 6.0664e-01,  ..., 4.8924e-01,\n",
       "            2.6073e-01, 6.5627e-02]],\n",
       "\n",
       "          [[6.8567e-01, 2.6169e-01, 8.8456e-01,  ..., 1.2724e-01,\n",
       "            1.9287e-03, 6.3375e-01],\n",
       "           [7.4601e-02, 6.5800e-01, 1.8389e-01,  ..., 2.2854e-01,\n",
       "            8.8119e-01, 3.9546e-01],\n",
       "           [1.2544e-01, 8.1739e-01, 9.5444e-01,  ..., 4.7358e-01,\n",
       "            9.3508e-02, 2.0757e-01],\n",
       "           ...,\n",
       "           [8.9770e-01, 2.2139e-01, 3.4240e-01,  ..., 3.5749e-01,\n",
       "            1.1210e-01, 6.4165e-01],\n",
       "           [9.7622e-01, 3.9384e-01, 4.7923e-02,  ..., 3.0440e-01,\n",
       "            5.6227e-01, 5.3939e-01],\n",
       "           [1.5171e-01, 8.5640e-01, 9.9997e-01,  ..., 4.1996e-01,\n",
       "            8.3901e-01, 9.3581e-01]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[3.7923e-01, 2.6437e-02, 3.4210e-01,  ..., 7.2667e-01,\n",
       "            8.2678e-01, 6.6464e-01],\n",
       "           [7.6880e-01, 7.7238e-01, 7.5126e-01,  ..., 3.2954e-01,\n",
       "            3.8086e-01, 3.8324e-01],\n",
       "           [5.2183e-01, 4.6273e-01, 1.6080e-01,  ..., 8.8483e-01,\n",
       "            6.5516e-01, 9.9698e-01],\n",
       "           ...,\n",
       "           [1.0709e-01, 8.2430e-01, 3.0920e-02,  ..., 4.5476e-01,\n",
       "            7.5554e-01, 2.5786e-01],\n",
       "           [5.9301e-01, 5.1754e-01, 7.6795e-01,  ..., 9.6515e-01,\n",
       "            2.0272e-01, 6.5533e-01],\n",
       "           [3.9287e-01, 8.1002e-01, 6.0033e-01,  ..., 3.0296e-01,\n",
       "            5.6952e-01, 1.6926e-01]],\n",
       "\n",
       "          [[8.9533e-01, 6.1128e-01, 5.0415e-01,  ..., 6.0762e-01,\n",
       "            1.6231e-01, 6.9967e-01],\n",
       "           [5.3685e-02, 3.8117e-01, 8.8477e-02,  ..., 4.0517e-01,\n",
       "            1.2226e-01, 8.5680e-02],\n",
       "           [3.6301e-01, 9.0033e-01, 1.3467e-01,  ..., 9.7176e-01,\n",
       "            4.5690e-01, 5.7798e-01],\n",
       "           ...,\n",
       "           [4.2535e-01, 6.4824e-01, 6.1597e-01,  ..., 4.6583e-01,\n",
       "            7.2831e-01, 2.6429e-01],\n",
       "           [7.0967e-01, 9.3068e-01, 9.9841e-02,  ..., 6.5908e-02,\n",
       "            1.8396e-01, 6.0179e-01],\n",
       "           [6.2538e-01, 5.2699e-01, 8.0046e-01,  ..., 3.8073e-02,\n",
       "            4.1569e-01, 4.4792e-02]],\n",
       "\n",
       "          [[9.3322e-01, 3.9698e-01, 4.6062e-01,  ..., 6.3176e-02,\n",
       "            7.2340e-01, 1.7555e-01],\n",
       "           [9.9751e-01, 4.8531e-01, 8.0949e-01,  ..., 2.4441e-01,\n",
       "            5.0181e-01, 2.1125e-01],\n",
       "           [9.1876e-01, 2.1386e-01, 2.6221e-01,  ..., 9.5660e-01,\n",
       "            2.7874e-01, 1.3043e-01],\n",
       "           ...,\n",
       "           [2.0899e-01, 6.1097e-01, 4.3440e-01,  ..., 6.1405e-01,\n",
       "            7.9224e-01, 5.3597e-01],\n",
       "           [2.7770e-01, 6.5340e-01, 8.2580e-01,  ..., 9.2251e-01,\n",
       "            1.4861e-01, 6.2245e-01],\n",
       "           [9.9243e-01, 7.5593e-01, 8.1724e-01,  ..., 6.4000e-01,\n",
       "            5.1160e-01, 7.6691e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[5.5634e-01, 4.1902e-01, 4.2172e-01,  ..., 5.0094e-01,\n",
       "            1.7372e-01, 8.5919e-01],\n",
       "           [5.2786e-01, 2.6655e-01, 1.3872e-03,  ..., 9.6470e-01,\n",
       "            7.8029e-01, 5.5247e-01],\n",
       "           [5.6829e-01, 5.7852e-01, 8.6177e-01,  ..., 9.2628e-01,\n",
       "            2.0776e-01, 1.8801e-02],\n",
       "           ...,\n",
       "           [3.4530e-01, 6.9442e-01, 4.6736e-01,  ..., 7.2148e-01,\n",
       "            6.2360e-01, 6.4734e-01],\n",
       "           [2.2824e-01, 8.4140e-01, 9.8714e-01,  ..., 3.7491e-01,\n",
       "            3.5615e-02, 2.8437e-02],\n",
       "           [5.2265e-01, 9.4861e-01, 4.5121e-01,  ..., 8.9851e-01,\n",
       "            1.1772e-01, 3.0110e-01]],\n",
       "\n",
       "          [[4.6675e-01, 9.9510e-01, 9.4704e-01,  ..., 6.0728e-01,\n",
       "            5.4667e-01, 2.9842e-02],\n",
       "           [1.7036e-01, 3.0922e-01, 7.1803e-02,  ..., 8.0841e-01,\n",
       "            5.3729e-01, 7.2445e-01],\n",
       "           [3.3971e-01, 6.5464e-01, 1.7866e-01,  ..., 4.7473e-01,\n",
       "            2.2830e-01, 7.3309e-01],\n",
       "           ...,\n",
       "           [4.2439e-01, 9.6583e-01, 5.7914e-02,  ..., 8.5654e-01,\n",
       "            9.6818e-01, 7.8105e-01],\n",
       "           [3.9254e-01, 4.3391e-01, 7.1093e-01,  ..., 8.3556e-01,\n",
       "            4.6083e-01, 8.1873e-01],\n",
       "           [2.4217e-01, 3.1513e-01, 3.8868e-01,  ..., 8.5926e-01,\n",
       "            9.9938e-02, 7.2380e-01]],\n",
       "\n",
       "          [[9.8565e-01, 4.1412e-01, 4.9905e-01,  ..., 8.8883e-01,\n",
       "            8.0008e-01, 1.1561e-01],\n",
       "           [8.7936e-01, 4.0243e-01, 9.2775e-01,  ..., 1.7426e-01,\n",
       "            6.6029e-01, 9.2412e-01],\n",
       "           [2.9696e-01, 2.1886e-02, 1.8805e-01,  ..., 6.3480e-02,\n",
       "            6.3660e-01, 8.8564e-01],\n",
       "           ...,\n",
       "           [6.4226e-01, 8.9240e-01, 1.3303e-01,  ..., 3.2155e-01,\n",
       "            5.1793e-02, 9.9933e-01],\n",
       "           [8.0987e-01, 3.4343e-01, 9.8924e-01,  ..., 5.4829e-01,\n",
       "            3.6760e-01, 6.3348e-01],\n",
       "           [8.4166e-01, 6.3623e-01, 4.0142e-01,  ..., 7.1144e-01,\n",
       "            5.6838e-01, 5.1144e-01]]],\n",
       "\n",
       "\n",
       "         [[[4.0023e-01, 9.4696e-01, 5.7146e-01,  ..., 9.5054e-01,\n",
       "            7.0881e-01, 1.6774e-01],\n",
       "           [5.2120e-01, 1.7669e-01, 8.3668e-01,  ..., 6.5828e-01,\n",
       "            1.8093e-01, 8.9297e-01],\n",
       "           [9.0837e-01, 3.4298e-01, 1.0534e-01,  ..., 6.4772e-01,\n",
       "            5.0010e-01, 9.5396e-01],\n",
       "           ...,\n",
       "           [5.1793e-01, 6.9185e-01, 4.3599e-02,  ..., 3.0913e-02,\n",
       "            7.1524e-01, 3.2566e-01],\n",
       "           [9.1578e-01, 6.0268e-01, 6.9627e-02,  ..., 3.1107e-01,\n",
       "            7.9585e-01, 1.5254e-01],\n",
       "           [6.3698e-01, 9.6340e-01, 4.4518e-01,  ..., 2.8854e-01,\n",
       "            3.8999e-01, 8.9526e-01]],\n",
       "\n",
       "          [[7.0142e-01, 1.3144e-01, 9.2002e-01,  ..., 1.5663e-01,\n",
       "            1.7996e-01, 3.3188e-01],\n",
       "           [9.4434e-01, 7.8619e-02, 3.6187e-01,  ..., 6.0225e-01,\n",
       "            7.9632e-01, 7.4226e-01],\n",
       "           [1.6446e-01, 7.4975e-01, 9.2409e-01,  ..., 1.6011e-01,\n",
       "            5.2466e-03, 3.7803e-01],\n",
       "           ...,\n",
       "           [3.2514e-02, 3.9630e-01, 1.7833e-02,  ..., 7.6471e-01,\n",
       "            3.2551e-01, 1.9013e-01],\n",
       "           [6.0469e-01, 2.3456e-01, 3.8362e-01,  ..., 5.3993e-01,\n",
       "            3.8105e-01, 6.0505e-01],\n",
       "           [6.8522e-01, 2.1285e-02, 3.8754e-01,  ..., 1.1254e-01,\n",
       "            4.2261e-01, 2.0883e-01]],\n",
       "\n",
       "          [[1.7580e-01, 4.5532e-01, 4.7226e-01,  ..., 4.5876e-01,\n",
       "            9.1902e-01, 8.2248e-01],\n",
       "           [4.3852e-01, 9.5470e-02, 8.9677e-01,  ..., 8.8447e-01,\n",
       "            1.3071e-01, 3.2341e-01],\n",
       "           [1.8063e-01, 1.9289e-01, 6.5738e-01,  ..., 1.7350e-01,\n",
       "            7.2392e-01, 3.9924e-01],\n",
       "           ...,\n",
       "           [3.3306e-01, 5.4566e-01, 8.8456e-01,  ..., 3.9972e-01,\n",
       "            2.1273e-01, 9.1929e-01],\n",
       "           [9.7176e-01, 9.1720e-01, 7.4638e-01,  ..., 9.2764e-01,\n",
       "            3.0262e-01, 6.4218e-01],\n",
       "           [7.3663e-01, 5.4021e-01, 2.7362e-01,  ..., 1.8230e-01,\n",
       "            3.2263e-01, 2.2105e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[6.8047e-01, 1.5417e-01, 7.7657e-01,  ..., 3.7903e-04,\n",
       "            1.6182e-01, 3.3334e-01],\n",
       "           [5.6767e-02, 3.5983e-01, 4.0396e-01,  ..., 5.2518e-01,\n",
       "            6.1094e-01, 7.7724e-01],\n",
       "           [7.9138e-02, 6.0595e-02, 4.4729e-01,  ..., 2.3392e-01,\n",
       "            2.9009e-01, 5.6306e-01],\n",
       "           ...,\n",
       "           [4.3858e-01, 7.0643e-01, 3.4236e-02,  ..., 6.6877e-01,\n",
       "            6.2833e-01, 5.3121e-01],\n",
       "           [9.1124e-02, 3.4015e-01, 5.4527e-01,  ..., 1.1862e-01,\n",
       "            1.2315e-01, 7.9368e-01],\n",
       "           [8.8353e-01, 5.9669e-01, 1.6168e-01,  ..., 1.9178e-01,\n",
       "            9.8884e-01, 1.9859e-01]],\n",
       "\n",
       "          [[9.0475e-01, 6.9412e-01, 9.8238e-01,  ..., 4.3180e-01,\n",
       "            6.4990e-02, 4.7203e-01],\n",
       "           [5.5456e-01, 7.2071e-01, 3.9836e-01,  ..., 9.2240e-01,\n",
       "            2.6416e-01, 9.1702e-04],\n",
       "           [4.1641e-01, 4.8070e-01, 9.3993e-01,  ..., 8.8521e-01,\n",
       "            9.6154e-02, 1.3012e-01],\n",
       "           ...,\n",
       "           [9.6599e-01, 5.1109e-01, 9.3926e-01,  ..., 6.5995e-01,\n",
       "            3.7566e-01, 1.5634e-01],\n",
       "           [8.5636e-01, 5.2796e-01, 5.3682e-01,  ..., 7.3493e-01,\n",
       "            9.1319e-01, 5.9765e-01],\n",
       "           [2.0750e-01, 5.5765e-01, 8.6756e-01,  ..., 5.5810e-01,\n",
       "            2.2543e-01, 8.2058e-01]],\n",
       "\n",
       "          [[6.8158e-01, 7.2800e-01, 2.7324e-01,  ..., 3.7797e-01,\n",
       "            7.8731e-01, 9.7102e-01],\n",
       "           [6.5580e-01, 1.5047e-01, 3.2172e-01,  ..., 3.2636e-01,\n",
       "            4.5758e-01, 7.8488e-01],\n",
       "           [6.1680e-01, 4.4425e-01, 8.7483e-01,  ..., 6.5729e-01,\n",
       "            9.0019e-01, 8.9469e-02],\n",
       "           ...,\n",
       "           [4.2171e-01, 7.7681e-01, 8.3335e-01,  ..., 5.5111e-01,\n",
       "            7.8777e-01, 6.1490e-01],\n",
       "           [4.5213e-01, 4.1773e-01, 2.7367e-01,  ..., 3.3367e-01,\n",
       "            1.2683e-01, 5.5208e-01],\n",
       "           [4.0696e-01, 7.6670e-01, 9.2246e-01,  ..., 8.9133e-01,\n",
       "            6.3705e-01, 8.6225e-01]]],\n",
       "\n",
       "\n",
       "         [[[9.2124e-01, 5.4775e-01, 9.9108e-01,  ..., 7.9483e-01,\n",
       "            3.7931e-01, 3.4015e-01],\n",
       "           [2.0805e-01, 6.8161e-01, 2.0647e-01,  ..., 8.1975e-01,\n",
       "            1.8654e-01, 2.4160e-01],\n",
       "           [3.7389e-01, 4.6758e-01, 6.6754e-02,  ..., 6.7729e-01,\n",
       "            3.3396e-01, 2.1264e-01],\n",
       "           ...,\n",
       "           [1.0826e-01, 5.2781e-01, 3.9832e-01,  ..., 4.4773e-01,\n",
       "            4.1593e-02, 2.0742e-01],\n",
       "           [8.9210e-01, 5.6257e-02, 3.6605e-01,  ..., 4.0550e-02,\n",
       "            1.2497e-01, 8.0256e-01],\n",
       "           [6.0996e-01, 6.5924e-01, 3.2444e-01,  ..., 8.5687e-02,\n",
       "            3.8033e-02, 6.4139e-01]],\n",
       "\n",
       "          [[3.8269e-01, 5.9925e-01, 8.1154e-01,  ..., 1.8311e-01,\n",
       "            3.3495e-01, 7.7061e-01],\n",
       "           [4.3980e-01, 1.3063e-01, 4.3922e-01,  ..., 6.1310e-01,\n",
       "            8.0502e-01, 8.1439e-01],\n",
       "           [6.4714e-02, 2.8719e-01, 2.7648e-01,  ..., 4.1768e-01,\n",
       "            6.3897e-01, 8.5255e-01],\n",
       "           ...,\n",
       "           [5.5336e-01, 1.1262e-02, 3.7302e-01,  ..., 1.3605e-01,\n",
       "            9.1991e-01, 7.1064e-01],\n",
       "           [7.1780e-01, 3.3557e-01, 9.4695e-01,  ..., 9.5429e-01,\n",
       "            3.7598e-01, 1.3398e-01],\n",
       "           [3.3176e-01, 2.8682e-01, 7.4006e-01,  ..., 1.7713e-01,\n",
       "            5.1664e-01, 6.4846e-01]],\n",
       "\n",
       "          [[5.0317e-01, 3.3021e-01, 1.9067e-01,  ..., 5.2191e-02,\n",
       "            4.7395e-01, 3.5710e-01],\n",
       "           [2.6313e-01, 3.2374e-01, 5.0730e-01,  ..., 7.9402e-01,\n",
       "            3.6432e-01, 5.4802e-01],\n",
       "           [9.0735e-01, 9.0965e-01, 9.1480e-02,  ..., 3.3013e-01,\n",
       "            2.8694e-01, 9.7456e-01],\n",
       "           ...,\n",
       "           [1.2408e-01, 3.0325e-01, 5.4479e-01,  ..., 5.4053e-01,\n",
       "            8.2731e-01, 3.5025e-01],\n",
       "           [9.9436e-01, 2.3604e-01, 1.4552e-01,  ..., 8.4245e-02,\n",
       "            9.5189e-01, 1.1136e-01],\n",
       "           [3.3905e-01, 8.8711e-01, 7.5540e-01,  ..., 9.5604e-01,\n",
       "            8.2267e-01, 6.0493e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[2.1732e-01, 6.3496e-01, 6.1005e-01,  ..., 2.3860e-02,\n",
       "            5.9427e-03, 6.9109e-01],\n",
       "           [9.1278e-01, 8.1746e-01, 2.9804e-01,  ..., 4.7549e-01,\n",
       "            1.0816e-01, 4.2450e-02],\n",
       "           [8.5085e-01, 8.0274e-01, 7.9116e-01,  ..., 2.5056e-01,\n",
       "            8.3315e-01, 9.0420e-01],\n",
       "           ...,\n",
       "           [7.0536e-02, 7.9010e-01, 3.9736e-02,  ..., 5.2077e-01,\n",
       "            7.3366e-01, 3.3153e-01],\n",
       "           [3.4655e-01, 4.0817e-01, 1.8812e-03,  ..., 5.6405e-01,\n",
       "            8.3029e-02, 8.7174e-01],\n",
       "           [2.8025e-01, 2.2498e-01, 8.4994e-01,  ..., 3.9071e-02,\n",
       "            6.8920e-01, 3.7268e-01]],\n",
       "\n",
       "          [[7.6599e-01, 5.4645e-01, 5.1955e-01,  ..., 6.7535e-01,\n",
       "            5.2738e-01, 3.7144e-01],\n",
       "           [3.5761e-01, 8.0493e-01, 3.7649e-01,  ..., 5.0713e-01,\n",
       "            4.1861e-01, 1.5061e-01],\n",
       "           [1.0811e-01, 7.7449e-01, 1.3381e-01,  ..., 8.6260e-01,\n",
       "            7.0118e-01, 2.9411e-01],\n",
       "           ...,\n",
       "           [5.8228e-01, 4.8149e-01, 3.3667e-01,  ..., 6.7104e-01,\n",
       "            2.6436e-01, 6.7041e-01],\n",
       "           [7.0136e-01, 1.7713e-01, 6.2340e-01,  ..., 1.9746e-01,\n",
       "            5.4419e-01, 4.6908e-01],\n",
       "           [8.6317e-01, 6.5058e-01, 8.7570e-01,  ..., 2.5085e-01,\n",
       "            2.3015e-01, 8.8973e-01]],\n",
       "\n",
       "          [[8.4101e-02, 9.4410e-01, 7.6268e-01,  ..., 4.4440e-01,\n",
       "            6.5003e-01, 7.1730e-02],\n",
       "           [1.4145e-01, 7.9956e-01, 1.1777e-01,  ..., 2.1992e-01,\n",
       "            5.3832e-01, 4.8538e-01],\n",
       "           [4.1557e-01, 1.5347e-01, 4.4604e-01,  ..., 7.2475e-01,\n",
       "            6.5420e-01, 4.9229e-02],\n",
       "           ...,\n",
       "           [1.4410e-01, 3.7323e-01, 9.1275e-01,  ..., 6.9432e-01,\n",
       "            4.2131e-02, 6.4572e-01],\n",
       "           [7.4282e-01, 7.0169e-01, 9.5566e-01,  ..., 9.7619e-01,\n",
       "            2.0090e-02, 1.1358e-02],\n",
       "           [7.8663e-02, 7.8192e-01, 7.3352e-01,  ..., 6.3576e-01,\n",
       "            2.4863e-01, 4.4770e-01]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x - torch.Size([1, 7, 500, 500, 500])\n",
    "\n",
    "# conv(x).shape # torch.Size([1, 1, 491, 491, 491])\n",
    "\n",
    "# and this takes ~2min to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x - torch.Size([1, 7, 500, 500, 500])\n",
    "\n",
    "# conv(x).shape \n",
    "\n",
    "# takes more than 8 min!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=100, stride=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 9, 9, 9])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x).shape # torch.Size([1, 1, 9, 9, 9])\n",
    "\n",
    "# takes 2 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=100, stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv(x).shape # torch.Size([1, 1, 41, 41, 41])\n",
    "\n",
    "# and this takes ~2min to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_X = 100\n",
    "NUM_Y = 100\n",
    "NUM_Z = 100\n",
    "BLOCK_INFO = 7\n",
    "NUM_ORIENTATION = 2\n",
    "\n",
    "BLOCK_TYPES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 100, 100, 100])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((BLOCK_INFO,NUM_X,NUM_Y,NUM_Z))\n",
    "x = x.unsqueeze(0)\n",
    "\n",
    "(N, C, D, H, W) = x.shape\n",
    "\n",
    "x.to(device)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100, 100])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=1)\n",
    "conv1(x).shape # torch.Size([1, 1, 100, 100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 100, 100, 100])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = nn.Conv3d(in_channels=1, out_channels=BLOCK_TYPES * NUM_ORIENTATION, kernel_size=1)\n",
    "conv2(conv1(x)).shape # torch.Size([1, 10, 100, 100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 2, 100, 100, 100])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = conv1(x)\n",
    "x = conv2(x)\n",
    "x = torch.reshape(x, (1, BLOCK_TYPES, NUM_ORIENTATION, NUM_X, NUM_Y, NUM_Z))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv = nn.Conv3d(in_channels=C, out_channels=1, kernel_size=13, stride=3)\n",
    "# conv(x).shape # torch.Size([1, 1, 30, 30, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2 = nn.Conv3d(in_channels=1, out_channels=BLOCK_TYPES * NUM_ORIENTATION, kernel_size=15, stride=1)\n",
    "# conv2(conv(x)).shape # torch.Size([1, 10, 16, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_t = torch.nn.ConvTranspose3d(in_channels=5, out_channels=10, kernel_size=1)\n",
    "# conv_t(conv(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = conv(x)\n",
    "# x = conv2(x)\n",
    "# x = torch.reshape(x, (1, 5, 2, 16, 16, 16))\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the maximum value: [3, 1, 89, 32, 15]\n"
     ]
    }
   ],
   "source": [
    "x=x.squeeze()\n",
    "\n",
    "# Find the index of the maximum value\n",
    "max_index = torch.argmax(x)\n",
    "\n",
    "# Convert the flat index to multidimensional indices\n",
    "indices = []\n",
    "for dim_size in reversed(x.shape):\n",
    "    indices.append((max_index % dim_size).item())\n",
    "    max_index //= dim_size\n",
    "\n",
    "# Reverse the list of indices to match the tensor's shape\n",
    "indices.reverse()\n",
    "\n",
    "print(\"Indices of the maximum value:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1228305101394653"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value = torch.max(x)\n",
    "max_value.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1228, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3, 1, 89, 32, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPACESHIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
